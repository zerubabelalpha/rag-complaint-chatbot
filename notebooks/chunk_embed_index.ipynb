{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cac15547",
            "metadata": {},
            "source": [
                "# RAG Pipeline: Chunking, Embedding, and Indexing\n",
                "\n",
                "This notebook orchestrates the process of converting processed CFPB complaint data into a searchable vector store. \n",
                "\n",
                "**Pipeline Steps:**\n",
                "1. Setup environment and HuggingFace cache.\n",
                "2. Load processed data from disk.\n",
                "3. Convert complaints to LangChain Documents.\n",
                "4. Split documents into smaller semantic chunks.\n",
                "5. Generate embeddings and build a FAISS vector index.\n",
                "6. Verify the index with retrieval tests."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ac5844b9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ HuggingFace cache set to: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Imports and setup complete!\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "\n",
                "# 1. Setup PROJECT_ROOT to allow importing from src/\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "# 2. Import config and setup HuggingFace cache\n",
                "from src import config\n",
                "config.setup_hf_cache()\n",
                "\n",
                "# 3. Import required custom modules\n",
                "from src.file_handling import load_processed_data\n",
                "from src.docs import dataframe_to_documents, print_document_sample\n",
                "from src.chunking import chunk_documents, get_chunk_stats\n",
                "from src.vectorstore import create_vector_store, load_vector_store, get_retriever, print_search_results\n",
                "\n",
                "print(\"✓ Imports and setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c2c6d447",
            "metadata": {},
            "source": [
                "## 1. Load Processed Data\n",
                "\n",
                "We load the data generated by the EDA notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "222103a6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Loaded 12,000 processed DATA from filtered_complaints.csv\n",
                        "✓ Found 'clean_narrative' for indexing\n",
                        "Snippet: during the whole time that i had wells fargo ive experienced on going issues that has never been res...\n",
                        "Total records loaded: 12,000\n"
                    ]
                }
            ],
            "source": [
                "# Load cleaned data\n",
                "processed_data_path = config.PROCESSED_DATA_PATH\n",
                "df = load_processed_data(processed_data_path)\n",
                "\n",
                "# Verify document text exists\n",
                "text_col = 'clean_narrative'\n",
                "if text_col in df.columns:\n",
                "    print(f\"✓ Found '{text_col}' for indexing\")\n",
                "    # Show snippet of first valid row\n",
                "    print(f\"Snippet: {df[text_col].iloc[0][:100]}...\")\n",
                "else:\n",
                "    print(f\"❌ ERROR: {text_col} not found in the dataset!\")\n",
                "\n",
                "print(f\"Total records loaded: {len(df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "84b8bfe8",
            "metadata": {},
            "source": [
                "## 2. Convert to LangChain Documents\n",
                "\n",
                "We use `src.docs` to convert rows into structured objects that LangChain understands, preserving metadata for retrieval."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "a859c2e4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Converted 12,000 rows to LangChain Documents\n",
                        "  Sample metadata keys: ['complaint_id', 'product', 'sub_product', 'issue', 'sub_issue', 'company', 'state', 'date_received', 'timely_response', 'consumer_disputed']\n",
                        "============================================================\n",
                        "DOCUMENT SAMPLE\n",
                        "============================================================\n",
                        "Content:\n",
                        "during the whole time that i had wells fargo ive experienced on going issues that has never been res was forced to close my account with a balance that did not belong to me. theres been a lot of unaut...\n",
                        "------------------------------------------------------------\n",
                        "Metadata:\n",
                        "  complaint_id: 7075210\n",
                        "  product: Checking or savings account\n",
                        "  sub_product: Checking account\n",
                        "  issue: Problem with a lender or other company charging your account\n",
                        "  sub_issue: Transaction was not authorized\n",
                        "  company: WELLS FARGO & COMPANY\n",
                        "  state: SC\n",
                        "  date_received: 2023-06-05\n",
                        "  timely_response: Yes\n",
                        "  consumer_disputed: None\n",
                        "============================================================\n"
                    ]
                }
            ],
            "source": [
                "docs = dataframe_to_documents(df)\n",
                "\n",
                "# Preview a document\n",
                "if docs:\n",
                "    print_document_sample(docs[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "edb60d52",
            "metadata": {},
            "source": [
                "## 3. Chunk the Documents\n",
                "\n",
                "Break long narratives into manageable pieces for better embedding search accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8ab5f67a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[OK] Created text splitter (chunk_size=500, overlap=50)\n",
                        "[OK] Chunking complete:\n",
                        "  Original documents: 12,000\n",
                        "  After chunking: 38,024\n",
                        "  Expansion ratio: 3.17x\n",
                        "\n",
                        "Chunking Stats: {'total_chunks': 38024, 'min_length': 3, 'max_length': 500, 'mean_length': 372.5, 'median_length': 411}\n"
                    ]
                }
            ],
            "source": [
                "# Splitting documents into chunks\n",
                "chunks = chunk_documents(docs)\n",
                "\n",
                "# Display chunk stats\n",
                "stats = get_chunk_stats(chunks)\n",
                "print(f\"\\nChunking Stats: {stats}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "83727f03",
            "metadata": {},
            "source": [
                "## 4. Create Embedding and Vector Store (FAISS)\n",
                "\n",
                "This step converts text into high-dimensional vectors and stores them in a local index."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "9bc4a65d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating vector store with 38,024 documents...\n",
                        "  Persist directory: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss\n",
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "  (First run will download ~80MB to c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "40dc77cb49de49d790dd0d0a54827198",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
                        "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
                        "  warnings.warn(message)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c47e41f2caee4829a75b0f71c64f80ee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6483c25dc38149dda0a89d195df7a7f4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c7319eae4c5d4d4da604c2aace9196e9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7660ff04c500473e9adced9dbc961268",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "476cdea85f5542548e246ab360598ef1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d8faa52f06d042f18a36f656affbc7da",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c6b5fdee3a9242cb9443848f4e78e9d5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "20d63ee7ad2b45a8ac7fb99f41c627cb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "015c811f3d69447a9270c210ed70ed24",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a9b8c403e7274cf483a36c2b47ba9f24",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Embedding model loaded\n",
                        "✓ FAISS index built (ntotal=38,024)\n",
                        "✓ Vector store persisted to c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss\n",
                        "✓ Vector store built and saved to disk.\n"
                    ]
                }
            ],
            "source": [
                "# Create and persist vector store\n",
                "# Note: On the first run, this download the model (~80MB)\n",
                "vectorstore = create_vector_store(chunks)\n",
                "print(\"✓ Vector store built and saved to disk.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81820f2f",
            "metadata": {},
            "source": [
                "## 5. Test Loading and Retrieval\n",
                "\n",
                "Verify that we can reload the index from disk and perform a search."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "81557b4f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading vector store from c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss...\n",
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "  (First run will download ~80MB to c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf)\n",
                        "✓ Embedding model loaded\n",
                        "✓ Vector store loaded (ntotal=38,024)\n",
                        "✓ Created retriever (k=3)\n",
                        "======================================================================\n",
                        "SEARCH RESULTS for: 'unauthorized charge on my credit card'\n",
                        "======================================================================\n",
                        "\n",
                        "--- Result 1 ---\n",
                        "Complaint ID: N/A\n",
                        "Product: N/A\n",
                        "Issue: N/A\n",
                        "Company: N/A\n",
                        "Chunk Index: 4\n",
                        "Content preview:\n",
                        ". furthermore, i did not have the credit card in my physical presence and eyesight the entire time i was in xxxx ( xx xx xxxx-xx xx xxxx ). i handed the card over to merchants on several occasions for them to run it through for other charges that i recognize ( like for a dinner or gas ). so, it is p...\n",
                        "\n",
                        "--- Result 2 ---\n",
                        "Complaint ID: N/A\n",
                        "Product: N/A\n",
                        "Issue: N/A\n",
                        "Company: N/A\n",
                        "Chunk Index: 0\n",
                        "Content preview:\n",
                        "my card was charge unauthorize. but credit card company is not willing to correct this charge....\n",
                        "\n",
                        "--- Result 3 ---\n",
                        "Complaint ID: N/A\n",
                        "Product: N/A\n",
                        "Issue: N/A\n",
                        "Company: N/A\n",
                        "Chunk Index: 0\n",
                        "Content preview:\n",
                        "there has been unauthorized charges of 2600.00 on a credit card that i have known as last four ( xxxx ) xxxx citi simplicity credit card, i have contacted their customer care and their security department indicating them of all these bogus charges and to this date nothing has been done about resolvi...\n",
                        "\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Test loading from disk\n",
                "vectorstore_v2 = load_vector_store()\n",
                "\n",
                "# Test retrieval\n",
                "query = \"unauthorized charge on my credit card\"\n",
                "retriever = get_retriever(vectorstore_v2, k=3)\n",
                "results = retriever.invoke(query)\n",
                "\n",
                "# Display results\n",
                "print_search_results(results, query)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7808e90",
            "metadata": {},
            "source": [
                "## 6. Explore Vector Store\n",
                "\n",
                "A quick look into the index content."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "acec8d7a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total vectors in index: 38,024\n",
                        "Sample chunk metadata from retriever result:\n",
                        "{'complaint_id': 3374042, 'product': 'Credit card or prepaid card', 'sub_product': 'General-purpose credit card or charge card', 'issue': 'Problem with a purchase shown on your statement', 'sub_issue': 'Card was charged for something you did not purchase with the card', 'company': 'CAPITAL ONE FINANCIAL CORPORATION', 'state': 'IL', 'date_received': '2019-09-13', 'timely_response': 'Yes', 'consumer_disputed': None, 'chunk_index': 4}\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Total vectors in index: {vectorstore_v2.index.ntotal:,}\")\n",
                "print(f\"Sample chunk metadata from retriever result:\")\n",
                "print(results[0].metadata)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.11.9)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
