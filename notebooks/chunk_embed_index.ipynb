{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# RAG Pipeline: Production-Level Indexing\n",
                "\n",
                "This notebook demonstrates the production-level indexing pipeline for the consumer complaint dataset. It focuses on efficiency by leveraging pre-computed embeddings.\n",
                "\n",
                "## Project Architecture & Flow\n",
                "\n",
                "1.  **Data Ingestion**: Raw consumer complaints are ingested (handled in `eda.ipynb`).\n",
                "2.  **Preprocessing**: Text is cleaned, sensitive info removed, and handled.\n",
                "3.  **Embedding Generation (Optimization)**:\n",
                "    *   Instead of generating embeddings on the fly for 1.3M+ records (which is slow), we use a **Pre-built Embedding Store** (`data/complaint_embeddings.parquet`).\n",
                "    *   This file contains `(text_chunk, embedding_vector, metadata)` triplets.\n",
                "4.  **Vector Store Construction**:\n",
                "    *   We load the parquet file and build a **FAISS Index**.\n",
                "    *   The index allows for millisecond-latency similarity search.\n",
                "5.  **RAG Inference**:\n",
                "    *   The application (`app.py`) loads this FAISS index.\n",
                "    *   User Query -> Embedding -> FAISS Search -> Top-K Context -> LLM -> Answer.\n",
                "\n",
                "### In This Notebook:\n",
                "We specifically handle **Step 4**: Efficiently loading/building the FAISS index from the pre-built parquet file and verifying it works."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[OK] HuggingFace cache set to: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Imports and setup complete!\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# allow imports from project root\n",
                "project_root = Path.cwd().parent\n",
                "sys.path.insert(0, str(project_root))\n",
                "\n",
                "from src import config\n",
                "config.setup_hf_cache()\n",
                "\n",
                "from src import vectorstore\n",
                "from src.chunking import get_chunk_stats\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "print(\"✓ Imports and setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load-logic",
            "metadata": {},
            "source": [
                "## 1. Efficient Vector Store Loading\n",
                "\n",
                "In production, we often avoid re-indexing 1.3M records by loading a pre-persisted FAISS index or building it from raw embeddings in batches."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "load-exec",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vector store path: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss\n",
                        "Pre-built embeddings: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\data\\complaint_embeddings.parquet\n",
                        "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
                        "  (First run will download ~80MB to c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\models\\hf)\n",
                        "[OK] Embedding model loaded\n",
                        "FAISS index not found at c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss\n",
                        "Building index from pre-built source: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\data\\complaint_embeddings.parquet\n",
                        "Opening parquet file: c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\data\\complaint_embeddings.parquet...\n",
                        "Total rows to process: 1,375,327\n",
                        "Initializing FAISS with first batch of 50,000...\n",
                        "  Progress: 50,000 / 1,375,327 (3.6%)\n",
                        "  Progress: 100,000 / 1,375,327 (7.3%)\n",
                        "  Progress: 150,000 / 1,375,327 (10.9%)\n",
                        "  Progress: 200,000 / 1,375,327 (14.5%)\n",
                        "  Progress: 250,000 / 1,375,327 (18.2%)\n",
                        "  Progress: 300,000 / 1,375,327 (21.8%)\n",
                        "  Progress: 350,000 / 1,375,327 (25.4%)\n",
                        "  Progress: 400,000 / 1,375,327 (29.1%)\n",
                        "  Progress: 450,000 / 1,375,327 (32.7%)\n",
                        "  Progress: 500,000 / 1,375,327 (36.4%)\n",
                        "  Progress: 550,000 / 1,375,327 (40.0%)\n",
                        "  Progress: 600,000 / 1,375,327 (43.6%)\n",
                        "  Progress: 650,000 / 1,375,327 (47.3%)\n",
                        "  Progress: 700,000 / 1,375,327 (50.9%)\n",
                        "  Progress: 750,000 / 1,375,327 (54.5%)\n",
                        "  Progress: 800,000 / 1,375,327 (58.2%)\n",
                        "  Progress: 850,000 / 1,375,327 (61.8%)\n",
                        "  Progress: 900,000 / 1,375,327 (65.4%)\n",
                        "  Progress: 950,000 / 1,375,327 (69.1%)\n",
                        "  Progress: 1,000,000 / 1,375,327 (72.7%)\n",
                        "  Progress: 1,050,000 / 1,375,327 (76.3%)\n",
                        "  Progress: 1,100,000 / 1,375,327 (80.0%)\n",
                        "  Progress: 1,150,000 / 1,375,327 (83.6%)\n",
                        "  Progress: 1,200,000 / 1,375,327 (87.3%)\n",
                        "  Progress: 1,250,000 / 1,375,327 (90.9%)\n",
                        "  Progress: 1,300,000 / 1,375,327 (94.5%)\n",
                        "  Progress: 1,350,000 / 1,375,327 (98.2%)\n",
                        "  Progress: 1,375,327 / 1,375,327 (100.0%)\n",
                        "[OK] Built FAISS index with 1,375,327 vectors.\n",
                        "Saving built index to c:\\Users\\Acer\\Documents\\KAIM_PROJECT\\TEST\\rag-complaint-chatbot\\vector_store\\faiss for future use...\n",
                        "\n",
                        "✓ Vector store active with 1,375,327 vectors.\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Vector store path: {config.VECTOR_STORE_DIR}\")\n",
                "print(f\"Pre-built embeddings: {config.PREBUILT_EMBEDDINGS_PATH}\")\n",
                "\n",
                "# Load existing or build from parquet\n",
                "# Set force_rebuild=True to ensure we use the pre-built parquet file if needed\n",
                "vs = vectorstore.load_vector_store(force_rebuild=False)\n",
                "print(f\"\\n✓ Vector store active with {vs.index.ntotal:,} vectors.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "retrieval-test",
            "metadata": {},
            "source": [
                "## 2. Verification through Semantic Search\n",
                "\n",
                "We test the index with a sample query to ensure retrieval is functional and metadata is correctly preserved."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "search-exec",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "======================================================================\n",
                        "SEARCH RESULTS for: 'I lost my credit card and there are fraudulent charges'\n",
                        "======================================================================\n",
                        "\n",
                        "--- Result 1 ---\n",
                        "Complaint ID: 2695792\n",
                        "Product: Credit card or prepaid card\n",
                        "Category: Credit Card\n",
                        "Issue: Problem with a purchase shown on your statement\n",
                        "Company: SYNCHRONY FINANCIAL\n",
                        "Chunk: 0/1\n",
                        "Content preview:\n",
                        "i lost my credit card and and their are fraudulent charges and transactions of 2500.00 . the charges do n't belong to me. i have never used my credit card....\n",
                        "\n",
                        "--- Result 2 ---\n",
                        "Complaint ID: 8236492\n",
                        "Product: Credit card\n",
                        "Category: Credit Card\n",
                        "Issue: Problem with a purchase shown on your statement\n",
                        "Company: Chime Financial Inc\n",
                        "Chunk: 0/1\n",
                        "Content preview:\n",
                        "i lost my credit debit card and unauthorized charges where submitted to my account....\n",
                        "\n",
                        "--- Result 3 ---\n",
                        "Complaint ID: 1409416\n",
                        "Product: Credit card\n",
                        "Category: Credit Card\n",
                        "Issue: Credit card protection / Debt protection\n",
                        "Company: JPMORGAN CHASE & CO.\n",
                        "Chunk: 0/1\n",
                        "Content preview:\n",
                        "i found fraudulent charges on my credit card....\n",
                        "\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "query = \"I lost my credit card and there are fraudulent charges\"\n",
                "results = vectorstore.search_similar(vs, query, k=3)\n",
                "\n",
                "vectorstore.print_search_results(results, query)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "metadata-deep-dive",
            "metadata": {},
            "source": [
                "### Inspecting Metadata and Chunks\n",
                "\n",
                "Good RAG requires precise metadata tracking (e.g., `chunk_index`, `complaint_id`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "metadata-exec",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sample Metadata:\n",
                        "  chunk_index: 0\n",
                        "  company: SYNCHRONY FINANCIAL\n",
                        "  complaint_id: 2695792\n",
                        "  date_received: 2017-10-07\n",
                        "  issue: Problem with a purchase shown on your statement\n",
                        "  product: Credit card or prepaid card\n",
                        "  product_category: Credit Card\n",
                        "  state: AZ\n",
                        "  sub_issue: Card was charged for something you did not purchase with the card\n",
                        "  total_chunks: 1\n",
                        "\n",
                        "Content Snippet:\n",
                        "i lost my credit card and and their are fraudulent charges and transactions of 2500.00 . the charges do n't belong to me. i have never used my credit card....\n"
                    ]
                }
            ],
            "source": [
                "sample_doc = results[0]\n",
                "print(\"Sample Metadata:\")\n",
                "for k, v in sample_doc.metadata.items():\n",
                "    print(f\"  {k}: {v}\")\n",
                "\n",
                "print(f\"\\nContent Snippet:\\n{sample_doc.page_content[:200]}...\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.11.9)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
